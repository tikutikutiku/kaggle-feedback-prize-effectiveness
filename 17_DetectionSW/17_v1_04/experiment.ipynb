{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144293, 8)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('../../input/feedback-prize-2021/train.csv')\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>neighbor_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A8445CABFECE</td>\n",
       "      <td>1.622576e+12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Drivers should not be able to use phones while...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>3 4 5 6 7 8 9 10 11 12 13 14</td>\n",
       "      <td>[POSITION]Drivers should not be able to use ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A8445CABFECE</td>\n",
       "      <td>1.622576e+12</td>\n",
       "      <td>86.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>Drivers who used their phone while operating a...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 3...</td>\n",
       "      <td>[POSITION]Drivers should not be able to use ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A8445CABFECE</td>\n",
       "      <td>1.622576e+12</td>\n",
       "      <td>203.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>According to an article by the Edgar Snyder Fi...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 5...</td>\n",
       "      <td>[POSITION]Drivers should not be able to use ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A8445CABFECE</td>\n",
       "      <td>1.622576e+12</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>In conclusion, drivers should not able to work...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>177 178 179 180 181 182 183 184 185 186 187 18...</td>\n",
       "      <td>[POSITION]Drivers should not be able to use ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6B4F7A0165B9</td>\n",
       "      <td>1.622644e+12</td>\n",
       "      <td>36.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>The ability to stay connected to people we kno...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ...</td>\n",
       "      <td>[LEAD]The ability to stay connected to people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107523</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2029.0</td>\n",
       "      <td>2123.0</td>\n",
       "      <td>misdeeds are when the advice-giver is purpose...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 6</td>\n",
       "      <td>354 355 356 357 358 359 360 361 362 363 364 36...</td>\n",
       "      <td>[CLAIM]The more similar iterations people give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107524</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2123.0</td>\n",
       "      <td>2702.0</td>\n",
       "      <td>An example of this is when you ask Generic_Nam...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>368 369 370 371 372 373 374 375 376 377 378 37...</td>\n",
       "      <td>[EVIDENCE]Misunderstandings are harder to avoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107525</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2703.0</td>\n",
       "      <td>2799.0</td>\n",
       "      <td>Now, I know what you probably saying \"But what...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Counterclaim 1</td>\n",
       "      <td>465 466 467 468 469 470 471 472 473 474 475 47...</td>\n",
       "      <td>[CLAIM]The best thing to do in a situation lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107526</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2817.0</td>\n",
       "      <td>2907.0</td>\n",
       "      <td>what are the odds that seven of your close fr...</td>\n",
       "      <td>Rebuttal</td>\n",
       "      <td>Rebuttal 1</td>\n",
       "      <td>487 488 489 490 491 492 493 494 495 496 497 49...</td>\n",
       "      <td>[CLAIM] misdeeds are when the advice-giver is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107527</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2907.0</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>The odds are in your favor; and the on the off...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>505 506 507 508 509 510 511 512 513 514 515 51...</td>\n",
       "      <td>[EVIDENCE]An example of this is when you ask G...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107528 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            essay_id  discourse_id  discourse_start  discourse_end  \\\n",
       "0       A8445CABFECE  1.622576e+12             18.0           85.0   \n",
       "1       A8445CABFECE  1.622576e+12             86.0          202.0   \n",
       "2       A8445CABFECE  1.622576e+12            203.0         1030.0   \n",
       "3       A8445CABFECE  1.622576e+12           1031.0         1243.0   \n",
       "4       6B4F7A0165B9  1.622644e+12             36.0          512.0   \n",
       "...              ...           ...              ...            ...   \n",
       "107523  AFEC37C2D43F  1.617803e+12           2029.0         2123.0   \n",
       "107524  AFEC37C2D43F  1.617803e+12           2123.0         2702.0   \n",
       "107525  AFEC37C2D43F  1.617803e+12           2703.0         2799.0   \n",
       "107526  AFEC37C2D43F  1.617803e+12           2817.0         2907.0   \n",
       "107527  AFEC37C2D43F  1.617803e+12           2907.0         3140.0   \n",
       "\n",
       "                                           discourse_text  \\\n",
       "0       Drivers should not be able to use phones while...   \n",
       "1       Drivers who used their phone while operating a...   \n",
       "2       According to an article by the Edgar Snyder Fi...   \n",
       "3       In conclusion, drivers should not able to work...   \n",
       "4       The ability to stay connected to people we kno...   \n",
       "...                                                   ...   \n",
       "107523   misdeeds are when the advice-giver is purpose...   \n",
       "107524  An example of this is when you ask Generic_Nam...   \n",
       "107525  Now, I know what you probably saying \"But what...   \n",
       "107526   what are the odds that seven of your close fr...   \n",
       "107527  The odds are in your favor; and the on the off...   \n",
       "\n",
       "              discourse_type      discourse_type_num  \\\n",
       "0                   Position              Position 1   \n",
       "1                      Claim                 Claim 1   \n",
       "2                   Evidence              Evidence 1   \n",
       "3       Concluding Statement  Concluding Statement 1   \n",
       "4                       Lead                  Lead 1   \n",
       "...                      ...                     ...   \n",
       "107523                 Claim                 Claim 6   \n",
       "107524              Evidence              Evidence 3   \n",
       "107525          Counterclaim          Counterclaim 1   \n",
       "107526              Rebuttal              Rebuttal 1   \n",
       "107527  Concluding Statement  Concluding Statement 1   \n",
       "\n",
       "                                         predictionstring  \\\n",
       "0                            3 4 5 6 7 8 9 10 11 12 13 14   \n",
       "1       15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 3...   \n",
       "2       36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 5...   \n",
       "3       177 178 179 180 181 182 183 184 185 186 187 18...   \n",
       "4       5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ...   \n",
       "...                                                   ...   \n",
       "107523  354 355 356 357 358 359 360 361 362 363 364 36...   \n",
       "107524  368 369 370 371 372 373 374 375 376 377 378 37...   \n",
       "107525  465 466 467 468 469 470 471 472 473 474 475 47...   \n",
       "107526  487 488 489 490 491 492 493 494 495 496 497 49...   \n",
       "107527  505 506 507 508 509 510 511 512 513 514 515 51...   \n",
       "\n",
       "                                            neighbor_text  \n",
       "0       [POSITION]Drivers should not be able to use ph...  \n",
       "1       [POSITION]Drivers should not be able to use ph...  \n",
       "2       [POSITION]Drivers should not be able to use ph...  \n",
       "3       [POSITION]Drivers should not be able to use ph...  \n",
       "4       [LEAD]The ability to stay connected to people ...  \n",
       "...                                                   ...  \n",
       "107523  [CLAIM]The more similar iterations people give...  \n",
       "107524  [EVIDENCE]Misunderstandings are harder to avoi...  \n",
       "107525  [CLAIM]The best thing to do in a situation lik...  \n",
       "107526  [CLAIM] misdeeds are when the advice-giver is ...  \n",
       "107527  [EVIDENCE]An example of this is when you ask G...  \n",
       "\n",
       "[107528 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../../00_EDA/00_v2_04/result/unlabeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = list(train_df.groupby('id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_id, df = samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000D23A521A'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59951</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>1.617735e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>Some people belive that the so called \"face\" o...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59952</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>1.617735e+12</td>\n",
       "      <td>170.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>It was not created by aliens, and there is no ...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59953</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>1.617735e+12</td>\n",
       "      <td>358.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>A mesa is a naturally occuring rock formation,...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>69 70 71 72 73 74 75 76 77 78 79 80 81 82 83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59954</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>1.617735e+12</td>\n",
       "      <td>438.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>This \"face\" on mars only looks like a face bec...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59955</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>1.617735e+12</td>\n",
       "      <td>627.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>Many conspiracy theorists believe that NASA is...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Counterclaim 1</td>\n",
       "      <td>117 118 119 120 121 122 123 124 125 126 127 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59956</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>1.617735e+12</td>\n",
       "      <td>722.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>These people would be very wrong. If NASA foun...</td>\n",
       "      <td>Rebuttal</td>\n",
       "      <td>Rebuttal 1</td>\n",
       "      <td>134 135 136 137 138 139 140 141 142 143 144 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59957</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>1.617735e+12</td>\n",
       "      <td>836.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>NASA's budget would increase drasticly, which ...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>154 155 156 157 158 159 160 161 162 163 164 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59958</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>1.617735e+12</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1343.0</td>\n",
       "      <td>So, NASA is not hiding life on Mars from us, a...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>186 187 188 189 190 191 192 193 194 195 196 19...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  discourse_id  discourse_start  discourse_end  \\\n",
       "59951  0000D23A521A  1.617735e+12              0.0          170.0   \n",
       "59952  0000D23A521A  1.617735e+12            170.0          357.0   \n",
       "59953  0000D23A521A  1.617735e+12            358.0          438.0   \n",
       "59954  0000D23A521A  1.617735e+12            438.0          626.0   \n",
       "59955  0000D23A521A  1.617735e+12            627.0          722.0   \n",
       "59956  0000D23A521A  1.617735e+12            722.0          836.0   \n",
       "59957  0000D23A521A  1.617735e+12            836.0         1014.0   \n",
       "59958  0000D23A521A  1.617735e+12           1015.0         1343.0   \n",
       "\n",
       "                                          discourse_text  \\\n",
       "59951  Some people belive that the so called \"face\" o...   \n",
       "59952  It was not created by aliens, and there is no ...   \n",
       "59953  A mesa is a naturally occuring rock formation,...   \n",
       "59954  This \"face\" on mars only looks like a face bec...   \n",
       "59955  Many conspiracy theorists believe that NASA is...   \n",
       "59956  These people would be very wrong. If NASA foun...   \n",
       "59957  NASA's budget would increase drasticly, which ...   \n",
       "59958  So, NASA is not hiding life on Mars from us, a...   \n",
       "\n",
       "             discourse_type      discourse_type_num  \\\n",
       "59951              Position              Position 1   \n",
       "59952              Evidence              Evidence 1   \n",
       "59953              Evidence              Evidence 2   \n",
       "59954                 Claim                 Claim 1   \n",
       "59955          Counterclaim          Counterclaim 1   \n",
       "59956              Rebuttal              Rebuttal 1   \n",
       "59957              Evidence              Evidence 3   \n",
       "59958  Concluding Statement  Concluding Statement 1   \n",
       "\n",
       "                                        predictionstring  \n",
       "59951  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...  \n",
       "59952  34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 4...  \n",
       "59953       69 70 71 72 73 74 75 76 77 78 79 80 81 82 83  \n",
       "59954  84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 9...  \n",
       "59955  117 118 119 120 121 122 123 124 125 126 127 12...  \n",
       "59956  134 135 136 137 138 139 140 141 142 143 144 14...  \n",
       "59957  154 155 156 157 158 159 160 161 162 163 164 16...  \n",
       "59958  186 187 188 189 190 191 192 193 194 195 196 19...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as opj\n",
    "\n",
    "text_path = opj('../../input/feedback-prize-2021/train/', f'{text_id}.txt')\n",
    "with open(text_path) as f:\n",
    "    text = f.read().rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some people belive that the so called \"face\" on mars was created by life on mars. This is not the case. The face on Mars is a naturally occuring land form called a mesa. It was not created by aliens, and there is no consiracy to hide alien lifeforms on mars. There is no evidence that NASA has found that even suggests that this face was created by aliens.\\n\\nA mesa is a naturally occuring rock formation, that is found on Mars and Earth. This \"face\" on mars only looks like a face because humans tend to see faces wherever we look, humans are obviously extremely social, which is why our brain is designed to recognize faces.\\n\\nMany conspiracy theorists believe that NASA is hiding life on Mars from the rest of the world. These people would be very wrong. If NASA found life on Mars, then they would get millions of people\\'s attention. NASA\\'s budget would increase drasticly, which means that their workers would get paid more. There is no good reason that NASA would hide life on Mars from the rest of the world.\\n\\nSo, NASA is not hiding life on Mars from us, and they are not trying to trick us into thinking that the \"face\" on mars is just a mesa, because it actually is. NASA hiding life would be illogical, because if they found life on Mars, they would make a lot of money, and we all know that the people at NASA aren\\'t illogical people.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = 'roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "text = 'Hello, I am Tom.'\n",
    "\n",
    "tokens = tokenizer(text, return_offsets_mapping=True)\n",
    "offset_mapping = tokens['offset_mapping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'Hello', ',', 'ĠI', 'Ġam', 'ĠTom', '.', '</s>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(tokens['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def strip_offset_mapping(text, offset_mapping):\n",
    "    ret = []\n",
    "    for start, end in offset_mapping:\n",
    "        match = list(re.finditer('\\S+', text[start:end]))\n",
    "        if len(match) == 0:\n",
    "            ret.append((start, end))\n",
    "        else:\n",
    "            span_start, span_end = match[0].span()\n",
    "            ret.append((start + span_start, start + span_end))\n",
    "    return np.array(ret)\n",
    "\n",
    "\n",
    "def get_word_offsets(text):\n",
    "    matches = re.finditer(\"\\S+\", text)\n",
    "    spans = []\n",
    "    words = []\n",
    "    for match in matches:\n",
    "        span = match.span()\n",
    "        word = match.group()\n",
    "        spans.append(span)\n",
    "        words.append(word)\n",
    "    assert tuple(words) == tuple(text.split())\n",
    "    return np.array(spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token slices of words (offset_mapping = character slices of tokens)\n",
    "\n",
    "import torch\n",
    "\n",
    "if True:\n",
    "    if True:\n",
    "        offset_mapping = np.array(tokens['offset_mapping'])\n",
    "        offset_mapping = strip_offset_mapping(text, offset_mapping)\n",
    "        \n",
    "        woff = get_word_offsets(text) # (num_words,2) : character slices of words\n",
    "        toff = offset_mapping # (num_tokens,2) : character slices of tokens\n",
    "        wx1, wx2 = woff.T # (num_words,) x 2\n",
    "        tx1, tx2 = toff.T # (num_tokens,) x 2\n",
    "        ix1 = np.maximum(wx1[..., None], tx1[None, ...]) # (num_words,num_tokens)\n",
    "        ix2 = np.minimum(wx2[..., None], tx2[None, ...]) # (num_words,num_tokens)\n",
    "        ux1 = np.minimum(wx1[..., None], tx1[None, ...]) # (num_words,num_tokens)\n",
    "        ux2 = np.maximum(wx2[..., None], tx2[None, ...]) # (num_words,num_tokens)\n",
    "        ious = (ix2 - ix1).clip(min=0) / (ux2 - ux1 + 1e-12) # (num_words,num_tokens)\n",
    "        assert (ious > 0).any(-1).all()\n",
    "        \n",
    "        word_boxes = []\n",
    "        for row in ious: # ious.shape=(num_words,num_tokens)\n",
    "            inds = row.nonzero()[0]\n",
    "            word_boxes.append([inds[0], 0, inds[-1] + 1, 1])\n",
    "        word_boxes = torch.FloatTensor(word_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL2TYPE = ('Lead', 'Position', 'Claim', 'Counterclaim', 'Rebuttal',\n",
    "              'Evidence', 'Concluding Statement')\n",
    "\n",
    "TYPE2LABEL = {t: l for l, t in enumerate(LABEL2TYPE)}\n",
    "\n",
    "# word slices of ground truth spans\n",
    "if True:\n",
    "    if True:\n",
    "        gt_spans = []\n",
    "        for _, row in df.iterrows():\n",
    "            winds = row['predictionstring'].split()\n",
    "            start = int(winds[0])\n",
    "            end = int(winds[-1])\n",
    "            span_label = TYPE2LABEL[row['discourse_type']]\n",
    "            gt_spans.append([start, end + 1, span_label])\n",
    "        gt_spans = torch.LongTensor(gt_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello, I'm Tom.\"\n",
    "#       012345678901234\n",
    "\n",
    "tokens = tokenizer(text, add_special_tokens=False, return_offsets_mapping=True)\n",
    "offset_mapping = tokens['offset_mapping']\n",
    "    \n",
    "woff = get_word_offsets(text)\n",
    "toff = offset_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ',', 'ĠI', \"'m\", 'ĠTom', '.']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(tokens['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  6],\n",
       "       [ 7, 10],\n",
       "       [11, 15]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "woff # [Hello(0,6), I'm(7,10), Tom.(11,15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 5), (5, 6), (7, 8), (8, 10), (11, 14), (14, 15)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toff # [Hello(0,5), ,(5,6), GI(7,8), 'm(8,10), GTom(11,14), .(14,15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token slices of words (offset_mapping = character slices of tokens)\n",
    "\n",
    "import torch\n",
    "\n",
    "if True:\n",
    "    if True:\n",
    "        offset_mapping = np.array(tokens['offset_mapping'])\n",
    "        offset_mapping = strip_offset_mapping(text, offset_mapping)\n",
    "        \n",
    "        woff = get_word_offsets(text) # (num_words,2) : character slices of words\n",
    "        toff = offset_mapping # (num_tokens,2) : character slices of tokens\n",
    "        wx1, wx2 = woff.T # (num_words,) x 2\n",
    "        tx1, tx2 = toff.T # (num_tokens,) x 2\n",
    "        ix1 = np.maximum(wx1[..., None], tx1[None, ...]) # (num_words,num_tokens)\n",
    "        ix2 = np.minimum(wx2[..., None], tx2[None, ...]) # (num_words,num_tokens)\n",
    "        ux1 = np.minimum(wx1[..., None], tx1[None, ...]) # (num_words,num_tokens)\n",
    "        ux2 = np.maximum(wx2[..., None], tx2[None, ...]) # (num_words,num_tokens)\n",
    "        ious = (ix2 - ix1).clip(min=0) / (ux2 - ux1 + 1e-12) # (num_words,num_tokens)\n",
    "        assert (ious > 0).any(-1).all()\n",
    "        \n",
    "        word_boxes = []\n",
    "        for row in ious: # ious.shape=(num_words,num_tokens)\n",
    "            inds = row.nonzero()[0]\n",
    "            word_boxes.append([inds[0], 0, inds[-1] + 1, 1])\n",
    "        word_boxes = torch.FloatTensor(word_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  6],\n",
       "        [ 7, 10],\n",
       "        [11, 15]]),\n",
       " array([[ 0,  5],\n",
       "        [ 5,  6],\n",
       "        [ 7,  8],\n",
       "        [ 8, 10],\n",
       "        [11, 14],\n",
       "        [14, 15]]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "woff, toff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  5,  7,  8, 11, 14],\n",
       "       [ 7,  7,  7,  8, 11, 14],\n",
       "       [11, 11, 11, 11, 11, 14]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  6,  6,  6,  6,  6],\n",
       "       [ 5,  6,  8, 10, 10, 10],\n",
       "       [ 5,  6,  8, 10, 14, 15]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  5,  7,  7,  7,  7],\n",
       "       [ 0,  5,  7,  8, 11, 11]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ux1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  6,  8, 10, 14, 15],\n",
       "       [10, 10, 10, 10, 14, 15],\n",
       "       [15, 15, 15, 15, 15, 15]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ux2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83333333 0.16666667 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.33333333 0.66666667 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.75       0.25      ]]\n"
     ]
    }
   ],
   "source": [
    "print(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 2., 1.],\n",
       "        [2., 0., 4., 1.],\n",
       "        [4., 0., 6., 1.]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 1 2 3'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([0,1,2,3])\n",
    "' '.join(a.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
