{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36765, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "      <th>Ineffective_0</th>\n",
       "      <th>Adequate_0</th>\n",
       "      <th>Effective_0</th>\n",
       "      <th>label</th>\n",
       "      <th>loss</th>\n",
       "      <th>...</th>\n",
       "      <th>Effective_3</th>\n",
       "      <th>Ineffective_4</th>\n",
       "      <th>Adequate_4</th>\n",
       "      <th>Effective_4</th>\n",
       "      <th>Ineffective_5</th>\n",
       "      <th>Adequate_5</th>\n",
       "      <th>Effective_5</th>\n",
       "      <th>Ineffective</th>\n",
       "      <th>Adequate</th>\n",
       "      <th>Effective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>0.002175</td>\n",
       "      <td>0.152980</td>\n",
       "      <td>0.011512</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.013028</td>\n",
       "      <td>0.149802</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>0.013616</td>\n",
       "      <td>0.150725</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.044812</td>\n",
       "      <td>0.919796</td>\n",
       "      <td>0.035392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>0.009333</td>\n",
       "      <td>0.152729</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>1</td>\n",
       "      <td>0.087332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006511</td>\n",
       "      <td>0.008662</td>\n",
       "      <td>0.154979</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>0.026612</td>\n",
       "      <td>0.136538</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>0.091948</td>\n",
       "      <td>0.881701</td>\n",
       "      <td>0.026351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>0.023451</td>\n",
       "      <td>0.141358</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>0.029492</td>\n",
       "      <td>0.135902</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.048600</td>\n",
       "      <td>0.115757</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0.172267</td>\n",
       "      <td>0.812169</td>\n",
       "      <td>0.015564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>0.055733</td>\n",
       "      <td>0.109495</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>1</td>\n",
       "      <td>0.420119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.032678</td>\n",
       "      <td>0.132563</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.056640</td>\n",
       "      <td>0.108651</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.236727</td>\n",
       "      <td>0.752566</td>\n",
       "      <td>0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>0.041290</td>\n",
       "      <td>0.124674</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>1</td>\n",
       "      <td>0.290297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.054301</td>\n",
       "      <td>0.111310</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.070796</td>\n",
       "      <td>0.094933</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.317408</td>\n",
       "      <td>0.675184</td>\n",
       "      <td>0.007408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
       "1  On my perspective, I think that the face is a ...       Position   \n",
       "2  I think that the face is a natural landform be...          Claim   \n",
       "3  If life was on Mars, we would know by now. The...       Evidence   \n",
       "4  People thought that the face was formed by ali...   Counterclaim   \n",
       "\n",
       "  discourse_effectiveness  Ineffective_0  Adequate_0  Effective_0  label  \\\n",
       "0                Adequate       0.002175    0.152980     0.011512      1   \n",
       "1                Adequate       0.009333    0.152729     0.004605      1   \n",
       "2                Adequate       0.023451    0.141358     0.001857      1   \n",
       "3                Adequate       0.055733    0.109495     0.001439      1   \n",
       "4                Adequate       0.041290    0.124674     0.000703      1   \n",
       "\n",
       "       loss  ...  Effective_3  Ineffective_4  Adequate_4  Effective_4  \\\n",
       "0  0.085691  ...     0.003841       0.013028    0.149802     0.003837   \n",
       "1  0.087332  ...     0.006511       0.008662    0.154979     0.003025   \n",
       "2  0.164698  ...     0.005504       0.029492    0.135902     0.001273   \n",
       "3  0.420119  ...     0.002196       0.032678    0.132563     0.001426   \n",
       "4  0.290297  ...     0.001962       0.054301    0.111310     0.001056   \n",
       "\n",
       "   Ineffective_5  Adequate_5  Effective_5  Ineffective  Adequate  Effective  \n",
       "0       0.013616    0.150725     0.002326     0.044812  0.919796   0.035392  \n",
       "1       0.026612    0.136538     0.003517     0.091948  0.881701   0.026351  \n",
       "2       0.048600    0.115757     0.002310     0.172267  0.812169   0.015564  \n",
       "3       0.056640    0.108651     0.001375     0.236727  0.752566   0.010708  \n",
       "4       0.070796    0.094933     0.000937     0.317408  0.675184   0.007408  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('../../input/feedback-prize-effectiveness/train.csv')\n",
    "stack_df = pd.read_csv('../../99_Ensemble/99_v1_02/result/stack_99_v1_02_27.csv')\n",
    "\n",
    "train_df = train_df[['discourse_id']].merge(stack_df, on='discourse_id', how='left')\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vectors found: 2196017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import gc\n",
    "\n",
    "with open(\"../../input/nlp-word-embeddings/Glove_Embeddings.txt\", 'rb') as handle: \n",
    "    data = handle.read()\n",
    "\n",
    "processed_data = pickle.loads(data)\n",
    "embeddings_index = processed_data['glove_embeddings_index']\n",
    "print('Word vectors found: {}'.format(len(embeddings_index)))\n",
    "\n",
    "del processed_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "def sent2vec(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    \n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(embeddings_index[w])\n",
    "        except:\n",
    "            M.append(embeddings_index['unk'])\n",
    "            continue\n",
    "    \n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(300)\n",
    "    \n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36765/36765 [00:09<00:00, 3936.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_vec_df: (36765, 300)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "glove_vec = [sent2vec(x) for x in tqdm(train_df[\"discourse_text\"].values)]\n",
    "col_list = ['discourse_glove_'+str(i) for i in range(300)]\n",
    "glove_vec_df = pd.DataFrame(np.array(glove_vec), columns=col_list, index=train_df['discourse_id'].values)\n",
    "print(f\"glove_vec_df: {glove_vec_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.merge(glove_vec_df.reset_index(), left_on='discourse_id', right_on='index', how='left')\n",
    "del train_df['index']; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['discourse_id', 'essay_id', 'discourse_text', 'discourse_type',\n",
       "       'discourse_effectiveness', 'Ineffective_0', 'Adequate_0', 'Effective_0',\n",
       "       'label', 'loss',\n",
       "       ...\n",
       "       'discourse_glove_290', 'discourse_glove_291', 'discourse_glove_292',\n",
       "       'discourse_glove_293', 'discourse_glove_294', 'discourse_glove_295',\n",
       "       'discourse_glove_296', 'discourse_glove_297', 'discourse_glove_298',\n",
       "       'discourse_glove_299'],\n",
       "      dtype='object', length=328)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load folds...\n"
     ]
    }
   ],
   "source": [
    "from os.path import join as opj\n",
    "\n",
    "class args:\n",
    "    fold_path = '../../00_EDA/00_v2_07/result/'\n",
    "    num_fold = 5\n",
    "    \n",
    "fold_path = args.fold_path\n",
    "import joblib\n",
    "print('load folds...')\n",
    "trn_ids_list = joblib.load(opj(fold_path,f'trn_ids_list.joblib'))\n",
    "val_ids_list = joblib.load(opj(fold_path,f'val_ids_list.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train_df['discourse_type_label'] = le.fit_transform(train_df['discourse_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = []\n",
    "for col_name in ['Ineffective','Adequate','Effective']:\n",
    "    cols += [col for col in train_df.columns if (col.startswith(col_name) and '_' in col)] \n",
    "    \n",
    "num_models = len(cols) // 3\n",
    "num_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "params = {'num_leaves': 128,\n",
    "         'min_data_in_leaf': 100, #200, \n",
    "         'objective':'multiclass',\n",
    "         #\"metric\": 'l2',\n",
    "         'max_depth': 8, #-1,\n",
    "         'learning_rate': 0.001, #0.05,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"bagging_fraction\": 0.85,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"feature_fraction\": 0.4, #0.20,\n",
    "         \"bagging_seed\": 42,\n",
    "         \"verbosity\": -1,\n",
    "         \"nthread\": -1,\n",
    "         \"random_state\": 69}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/takesako/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/takesako/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "fold0 : CV=0.5805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/takesako/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/takesako/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=-1 will be ignored. Current value: num_threads=-1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.85, subsample=1.0 will be ignored. Current value: bagging_fraction=0.85\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-49589e21a145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m               \u001b[0;31m#eval_metric='l2',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m               early_stopping_rounds=100)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    970\u001b[0m                     \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m                     callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[1;32m    973\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0minit_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m         )\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    290\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3021\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   3022\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3023\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   3024\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "import pickle\n",
    "import os\n",
    "os.makedirs('./result', exist_ok=True)\n",
    "\n",
    "#cols = cols + ['discourse_type_label']\n",
    "cols = ['discourse_type_label'] + [col for col in train_df.columns if col.startswith('discourse_glove_')] + cols\n",
    "\n",
    "score_list = []\n",
    "oof_df = []\n",
    "for fold in range(args.num_fold):\n",
    "    trn_df = train_df[train_df['essay_id'].isin(trn_ids_list[fold])].reset_index(drop=True)\n",
    "    val_df = train_df[train_df['essay_id'].isin(val_ids_list[fold])].reset_index(drop=True)\n",
    "\n",
    "    model = lgb.LGBMClassifier(**params, n_estimators = 20000)\n",
    "    model.fit(trn_df[cols].values, \n",
    "              trn_df['label'].values ,\n",
    "              eval_set=[(val_df[cols].values, val_df['label'].values)], \n",
    "              #eval_metric='l2',\n",
    "              verbose=0, \n",
    "              early_stopping_rounds=100)\n",
    "\n",
    "    pred = model.predict_proba(X=val_df[cols].values)\n",
    "    target = val_df['label'].values\n",
    "    score = log_loss(target, pred, labels=[0,1,2])\n",
    "    print('fold{} : CV={:.4f}'.format(fold, score))\n",
    "    score_list.append(score)\n",
    "    val_df['oof_ineffective'] = pred[:,0]\n",
    "    val_df['oof_adequate'] = pred[:,1]\n",
    "    val_df['oof_effective'] = pred[:,2]\n",
    "    oof_df.append(val_df)\n",
    "    # save model\n",
    "    joblib.dump(model, f'./result/lgb_fold{fold}.joblib')\n",
    "    \n",
    "CV = sum(score_list) / len(score_list)\n",
    "print('CV={:.4f}'.format(CV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(le, f'./result/label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df = pd.concat(oof_df).reset_index(drop=True)\n",
    "oof_df = train_df[['discourse_id']].merge(oof_df, on='discourse_id', how='left')\n",
    "oof_df.to_csv(f'./result/oof_cat.csv', index=False)\n",
    "print(oof_df.shape)\n",
    "oof_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in oof_df.columns if col.startswith('oof_')]\n",
    "\n",
    "oof_score = log_loss(oof_df['label'].values, oof_df[cols].values, labels=[0,1,2])\n",
    "print('oof={:.4f}'.format(oof_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
