{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "heated-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = '05_v2_09'\n",
    "FOLD_PATH = '../../00_EDA/00_v2_05/result/'\n",
    "MODEL = 'microsoft/deberta-v3-large'\n",
    "#'microsoft/deberta-v3-base'\n",
    "#'funnel-transformer/xlarge'\n",
    "#'ahotrod/electra_large_discriminator_squad2_512'\n",
    "#'funnel-transformer/xlarge'\n",
    "#'microsoft/deberta-large'\n",
    "#'anferico/bert-for-patents'\n",
    "#'microsoft/deberta-v3-base'\n",
    "#'microsoft/cocolm-large'\n",
    "LR = 8e-6 #2e-5\n",
    "HEAD_LR = 8e-6 #2e-4\n",
    "SEED = 100\n",
    "TRN_BS = 1\n",
    "VAL_BS = 1\n",
    "ACCUM_STEP = 1 #4 #16\n",
    "EPOCHS = 6 #2\n",
    "STOP_EPOCH = 6 #2\n",
    "RESTART = 1\n",
    "HIDDEN_DROP_PROB = 0.1\n",
    "P_DROP = 0.5\n",
    "#RNN = 'none'\n",
    "WARMUP_RATIO = 0.05 #0.1\n",
    "#LOSS = 'xentropy'\n",
    "#HEAD = 'simple'\n",
    "#AUG = 'false' #'mixup'\n",
    "#MIXUP_ALPHA = 1.0\n",
    "#P_AUG = 0\n",
    "#AUG_STOP_EPOCH = 2\n",
    "#MSD = 'false'\n",
    "#MULTI_LAYERS = 1\n",
    "EVAL_STEP = -1 #100\n",
    "#NUM_LABELS = 3\n",
    "#NUM_LABELS_2 = 7\n",
    "#ADV_SIFT = 'false'\n",
    "FP16 ='false'\n",
    "WD = 0.01\n",
    "#FREEZE = 'false'\n",
    "#MAX_LENGTH = 1024\n",
    "#MULTI_TASK = 'false'\n",
    "#W_MT = 1.0 #0.5\n",
    "#PREPROCESSED_DATA_PATH = '../../00_EDA/00_v2_01/result/train.csv'\n",
    "#'../../00_EDA/00_v1_09/result/train.csv'\n",
    "#AWP = 'false'\n",
    "#AWP_LR = 1.0\n",
    "#AWP_EPS = 0.01\n",
    "#AWP_START_EPOCH = 1\n",
    "MASK_PROB = 0.8\n",
    "MASK_RATIO = 0.3\n",
    "CP = 'true'\n",
    "SCHEDULER = 'cosine_hard'\n",
    "NUM_CYCLES = EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adult-alabama",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.2\n",
      "train_df.shape =  (144293, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (115526, 8)\n",
      "val_df.shape =  (28767, 8)\n",
      "2022-07-19 23:39:05.455178: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2022-07-19 23:39:05.455203: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loaded 12475 samples.\n",
      "Loaded 3119 samples.\n",
      "num_train_steps =  74850\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "self.warmup_ratio =  0.05\n",
      "self.num_train_steps =  74850\n",
      "num_warmup_steps =  3742\n",
      "\n",
      "lr :  [0.0, 0.0, 0.0]\n",
      "100%|███████████| 12475/12475 [1:19:38<00:00,  2.61it/s, loss=3.57, score=0.502]\n",
      "100%|███████████████████████████████████████| 3119/3119 [10:31<00:00,  4.94it/s]\n",
      "epoch 1: trn_loss = 3.5749, val_loss = 2.4256, trn_score = 0.5018, val_score = 0.6934\n",
      "trn_obj_loss=1.8786, trn_reg_loss=0.5086, trn_cls_loss=1.1877\n",
      "val_obj_loss=1.2250, val_reg_loss=0.3442, val_cls_loss=0.8564\n",
      "model (best loss) saved\n",
      "model (best score) saved\n",
      "\n",
      "lr :  [1.2905315769786836e-06, 1.2905315769786836e-06, 1.2905315769786836e-06]\n",
      "100%|███████████| 12475/12475 [1:21:11<00:00,  2.56it/s, loss=2.62, score=0.679]\n",
      "100%|███████████████████████████████████████| 3119/3119 [10:41<00:00,  4.86it/s]\n",
      "epoch 2: trn_loss = 2.6192, val_loss = 2.3088, trn_score = 0.6790, val_score = 0.7073\n",
      "trn_obj_loss=1.3505, trn_reg_loss=0.3731, trn_cls_loss=0.8956\n",
      "val_obj_loss=1.1857, val_reg_loss=0.3196, val_cls_loss=0.8035\n",
      "model (best loss) saved\n",
      "model (best score) saved\n",
      "\n",
      "lr :  [8.432094600802182e-07, 8.432094600802182e-07, 8.432094600802182e-07]\n",
      "100%|███████████| 12475/12475 [1:20:46<00:00,  2.57it/s, loss=2.46, score=0.705]\n",
      "100%|███████████████████████████████████████| 3119/3119 [10:27<00:00,  4.97it/s]\n",
      "epoch 3: trn_loss = 2.4640, val_loss = 2.2765, trn_score = 0.7050, val_score = 0.7126\n",
      "trn_obj_loss=1.2756, trn_reg_loss=0.3439, trn_cls_loss=0.8445\n",
      "val_obj_loss=1.1877, val_reg_loss=0.3072, val_cls_loss=0.7815\n",
      "model (best loss) saved\n",
      "model (best score) saved\n",
      "\n",
      "lr :  [4.819721976388868e-07, 4.819721976388868e-07, 4.819721976388868e-07]\n",
      "100%|███████████| 12475/12475 [1:20:20<00:00,  2.59it/s, loss=2.36, score=0.723]\n",
      "100%|███████████████████████████████████████| 3119/3119 [10:24<00:00,  4.99it/s]\n",
      "epoch 4: trn_loss = 2.3605, val_loss = 2.2559, trn_score = 0.7235, val_score = 0.7145\n",
      "trn_obj_loss=1.2290, trn_reg_loss=0.3246, trn_cls_loss=0.8070\n",
      "val_obj_loss=1.1814, val_reg_loss=0.3018, val_cls_loss=0.7727\n",
      "model (best loss) saved\n",
      "model (best score) saved\n",
      "\n",
      "lr :  [2.1667063555926046e-07, 2.1667063555926046e-07, 2.1667063555926046e-07]\n",
      "100%|███████████| 12475/12475 [1:22:04<00:00,  2.53it/s, loss=2.28, score=0.739]\n",
      "100%|███████████████████████████████████████| 3119/3119 [10:50<00:00,  4.80it/s]\n",
      "epoch 5: trn_loss = 2.2810, val_loss = 2.2755, trn_score = 0.7388, val_score = 0.7144\n",
      "trn_obj_loss=1.1953, trn_reg_loss=0.3087, trn_cls_loss=0.7770\n",
      "val_obj_loss=1.2002, val_reg_loss=0.3003, val_cls_loss=0.7750\n",
      "\n",
      "lr :  [5.4539478225454015e-08, 5.4539478225454015e-08, 5.4539478225454015e-08]\n",
      "100%|████████████| 12475/12475 [1:21:47<00:00,  2.54it/s, loss=2.19, score=0.75]\n",
      "100%|███████████████████████████████████████| 3119/3119 [10:11<00:00,  5.10it/s]\n",
      "epoch 6: trn_loss = 2.1917, val_loss = 2.2900, trn_score = 0.7502, val_score = 0.7127\n",
      "trn_obj_loss=1.1512, trn_reg_loss=0.2929, trn_cls_loss=0.7476\n",
      "val_obj_loss=1.2172, val_reg_loss=0.2971, val_cls_loss=0.7757\n",
      "epoch_best 4, val_loss_best 2.25589, val_score_best 0.71455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FOLD = 0\n",
    "\n",
    "!python ../$VERSION/train.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED \\\n",
    "--lr $LR --head_lr $HEAD_LR --trn_batch_size $TRN_BS --val_batch_size $VAL_BS \\\n",
    "--warmup_ratio $WARMUP_RATIO \\\n",
    "--epochs $EPOCHS --accumulate_grad_batches $ACCUM_STEP --eval_step $EVAL_STEP --stop_epoch $STOP_EPOCH \\\n",
    "--restart_epoch $RESTART --fp16 $FP16 --weight_decay $WD --mask_prob $MASK_PROB --mask_ratio $MASK_RATIO \\\n",
    "--check_pointing $CP --scheduler $SCHEDULER --num_cycles $NUM_CYCLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-ebony",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "representative-council",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "excited-cylinder",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.2\n",
      "2022-07-20 08:49:08.405211: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2022-07-20 08:49:08.405232: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "train_df.shape =  (144293, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (115526, 8)\n",
      "val_df.shape =  (28767, 8)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loaded 3119 samples.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|███████████████████████████████████████| 3119/3119 [06:04<00:00,  8.57it/s]\n",
      "val_loss=2.2559, val_score=0.7145\n",
      "val_obj_loss=1.1814, val_reg_loss=0.3018, val_cls_loss=0.7727\n",
      "save raw_oof_fold0...\n",
      "save raw_oof_fold0, done\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TEST_SCORE_THR = 0.5\n",
    "\n",
    "!python ../$VERSION/validation.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold 0 --seed $SEED --val_batch_size $VAL_BS \\\n",
    "--test_score_thr $TEST_SCORE_THR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "catholic-istanbul",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.2\n",
      "2022-07-20 08:55:35.403167: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2022-07-20 08:55:35.403187: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "train_df.shape =  (144293, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (115526, 8)\n",
      "val_df.shape =  (28767, 8)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loaded 3119 samples.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|███████████████████████████████████████| 3119/3119 [06:04<00:00,  8.56it/s]\n",
      "val_loss=2.2559, val_score=0.7179\n",
      "val_obj_loss=1.1814, val_reg_loss=0.3018, val_cls_loss=0.7727\n",
      "save raw_oof_fold0...\n",
      "save raw_oof_fold0, done\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TEST_SCORE_THR = 0.6 #0.5\n",
    "\n",
    "!python ../$VERSION/validation.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold 0 --seed $SEED --val_batch_size $VAL_BS \\\n",
    "--test_score_thr $TEST_SCORE_THR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-penetration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "expected-runner",
   "metadata": {},
   "source": [
    "# SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "powered-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../$VERSION/swa.py --work_dir ./result/$VERSION/ --fold 0 --seed $SEED --start_epoch 2 --end_epoch 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-visibility",
   "metadata": {},
   "source": [
    "# Validation with SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "comparable-german",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.10.2\n",
      "2022-07-20 18:53:27.234043: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2022-07-20 18:53:27.234066: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "train_df.shape =  (144293, 8)\n",
      "load folds...\n",
      "trn_df.shape =  (115526, 8)\n",
      "val_df.shape =  (28767, 8)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loaded 3119 samples.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|███████████████████████████████████████| 3119/3119 [06:10<00:00,  8.42it/s]\n",
      "val_loss=2.2996, val_score=0.7196\n",
      "val_obj_loss=1.1963, val_reg_loss=0.3099, val_cls_loss=0.7934\n",
      "save raw_oof_fold0...\n",
      "save raw_oof_fold0, done\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TEST_SCORE_THR = 0.6 #0.5\n",
    "\n",
    "FOLD = 0\n",
    "WEIGHT_PATH = f'./result/{VERSION}/model_seed{SEED}_fold{FOLD}_swa.pth'\n",
    "\n",
    "!python ../$VERSION/validation.py --model $MODEL --version $VERSION --fold_path $FOLD_PATH --fold $FOLD --seed $SEED --val_batch_size $VAL_BS \\\n",
    "--test_score_thr $TEST_SCORE_THR --weight_path $WEIGHT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-mobile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-document",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-uruguay",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-avenue",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
